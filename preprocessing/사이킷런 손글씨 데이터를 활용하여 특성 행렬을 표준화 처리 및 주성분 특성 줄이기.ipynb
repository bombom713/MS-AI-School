{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dddebb",
   "metadata": {},
   "source": [
    "# 사이킷런 손글씨 데이터를 활용하여 특성 행렬을 표준화 처리 및 주성분 특성 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ddb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030a9b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.33501649 -0.04308102 ... -1.14664746 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -1.09493684 ...  0.54856067 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -1.09493684 ...  1.56568555  1.6951369\n",
      "  -0.19600752]\n",
      " ...\n",
      " [ 0.         -0.33501649 -0.88456568 ... -0.12952258 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -0.67419451 ...  0.8876023  -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649  1.00877481 ...  0.8876023  -0.26113572\n",
      "  -0.19600752]]\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()  # 8x8 크기의 손글씨 숫자 데이터 로드\n",
    "features = StandardScaler().fit_transform(digits.data)  # 특성 행렬을 표준화 처리\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370b417",
   "metadata": {},
   "source": [
    "1. StandardScaler()<br>\n",
    "Scikit-learn의 전처리(preprocessing) 모듈에서 제공되는 클래스 중 하나입니다.<br>\n",
    "이 클래스는 데이터를 평균이 0, 분산이 1인 가우시안 정규 분포(standard normal distribution)로 변환합니다.<br>\n",
    "<br>\n",
    "2. digits.data<br>\n",
    "digits 데이터셋에서 숫자 이미지의 각 픽셀 값을 포함하는 배열<br>\n",
    "<br> \n",
    "3. fit_transform()<br>\n",
    "StandardScaler 클래스에는 데이터를 변환하는 두 가지 단계가 있습니다.<br>\n",
    "첫째, 모델을 학습(fit)하고, 둘째, 학습된 모델을 사용하여 데이터를 변환(transform)합니다.<br>\n",
    "fit_transform() 메서드는 이 두 단계를 한 번에 수행합니다.<br>\n",
    "즉, 데이터를 표준화(normalize)하고, 변환된 값을 반환합니다.<br>\n",
    "따라서 위의 코드는 digits 데이터셋의 특성을 가우시안 정규 분포로 변환한 후, 변환된 값을 featuress 변수에 할당 이렇게 정규화를 수행하면, 모델이 데이터를 더 잘 이해하고, 모델의 예측 성능을 향상 시킬 수 있습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67eaace",
   "metadata": {},
   "source": [
    "# 99%의 분산을 유지하도록 PCA 클래스 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "features_pca = pca.fit_transform(features)  # PCA 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37669fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수 >> 64\n",
      "줄어든특성 개수 >>  54\n"
     ]
    }
   ],
   "source": [
    "print(\"원본 특성 개수 >>\", features.shape[1])\n",
    "print(\"줄어든특성 개수 >> \", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21f793",
   "metadata": {},
   "source": [
    "1. PCA 클래스: Scikit-learn의 decomposition 모듈에서 제공되는 클래스 중 하나입니다.<br>\n",
    "PCA는 데이터셋의 차원을 감소시키는 기술로, 데이터셋에서 가장 중요한 특성만 추출하여 새로운 차원 축으로 변환합니다.<br>\n",
    "이를 통해 데이터셋의 노이즈(noise)를 제거하고, 더욱 빠르고 효율적인 학습이 가능해집니다.<br>\n",
    "<br>\n",
    "2. n_components: PCA 클래스의 인자 중 하나로, 추출할 주성분(principal component)의 수를 지정합니다.<br>\n",
    "여기서는 99%의 분산(variance)을 유지하도록 설정되어 있습니다.<br>\n",
    "이는 데이터셋에서 99%의 정보가 유지되도록 차원을 축소하는 것을 의미합니다.<br>\n",
    "<br>\n",
    "3. whiten: PCA 클래스의 인자 중 하나로, True로 설정할 경우 PCA의 결과로 나오는 주성분들이 서로 독립적인 값이 되도록 백색화(whitening)를 수행합니다.<br>\n",
    "백색화를 하면 각 주성분의 분산이 1이 되고, 상관 관계가 없는 성분들로 구성된 새로운 특성 공간이 만들어집니다.<br>\n",
    "<br>\n",
    "4. fit_transform(): PCA 클래스에는 fit()과 transform() 메서드가 있습니다.<br>\n",
    "fit() 메서드는 PCA 모델을 학습하고, transform() 메서드는 학습된 모델을 사용하여 데이터를 변환합니다.<br>\n",
    "fit_transform() 메서드는 이 두 단계를 한 번에 수행합니다.<br>\n",
    "위의 같이 PCA이용하면 99%의 분산을 유지하도록 새로운 특성(feature) 공간으로 변환하고 있습니다.<br>\n",
    "결과적으로, 원본 데이터셋의 특성 개수는 features.shape[1]으로 확인할 수 있고, PCA를 수행하여 감소된 특성 개수는 features_pca.shape[1]으로 확인할 수 있습니다.<br>\n",
    "이렇게 차원 축소를 수행하면, 모델의 학습 시간을 단축시키고, 과적합(overfitting)을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65e292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
