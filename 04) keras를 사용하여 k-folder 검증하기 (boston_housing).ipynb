{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cae18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 집값 데이터를 가져옵시다. \n",
    "from keras.datasets import boston_housing\n",
    "(train_data, train_labels),(test_data, test_labels) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423bce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "# 13개의 특성이 있고 데이터의 수가 매우 적습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa5a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2\n",
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(train_data[0])  # 데이터의 수치가 들쭉날쭉한 걸 보니 스케일링을 통해 수치를 맞춰주는 작업이 필요할 것 같네요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b8a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "       -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "        1.14850044,  0.44807713,  0.8252202 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스케일링으로 데이터 전처리를 해봅시다.\n",
    "mean = train_data.mean(axis=0)  # 각 컬럼 별로 평균을 구합니다. 가로가 0, 세로가 1입니다.\n",
    "train_data -= mean  # 학습데이터에서 평균을 낸 값을 뺍니다. train_data = train_data - mean과 같은 표현입니다.\n",
    "std = train_data.std(axis=0)  # 표준편차를 각 컬럼 별로 구해봅시다.\n",
    "train_data /= std  # 학습데이터를 표준편차로 나눠봅시다.\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0795e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 제작해봅시다. 신경망 제작은 모델구성과 같은 말입니다.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1])))\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(1))\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "\n",
    "# K겹 또는 K폴더 검증이란, 데이터가 얼마 없을 때 데이터를 3분할 해서 처음엔 검증, 훈련, 훈련 두번째엔 훈련, 검증, 훈련 세번째엔 훈련, 훈련, 검증 식으로 모든 데이터를 교차로 싹 도는 방법을 의미합니다.\n",
    "# 근데 이 경우, 반복해서 데이터를 초기화해야하는 번거로움이 있기 때문에 데이터를 초기화 해서 계속 검증을 돌리는 함수를 만들어 봅시다.\n",
    "def build_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212189ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴더 # 0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 8.0118 - mse: 8.0118\n",
      "8.01176643371582 8.01176643371582\n",
      "처리중인 폴더 # 1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 9.1382 - mse: 9.1382\n",
      "9.138200759887695 9.138200759887695\n",
      "처리중인 폴더 # 2\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.5752 - mse: 13.5752\n",
      "13.575154304504395 13.575154304504395\n",
      "처리중인 폴더 # 3\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.6438 - mse: 11.6438\n",
      "11.64377498626709 11.64377498626709\n"
     ]
    }
   ],
   "source": [
    "# 함수를 만들었으니 이제 K-folder 검증을 사용해 훈련 검증을 해봅시다.\n",
    "import numpy as np\n",
    "\n",
    "k=4  # folder의 갯수를 4로 지정합니다.\n",
    "num_val_samples = len(train_data)//k  # 샘플의 갯수(한 폴더의 데이터 수)는 101개씩 4덩이로 쪼개지면 되겠네요.\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):  # K의 숫자만큼 반복하게 됩니다.\n",
    "    print('처리중인 폴더 #', i)\n",
    "    \n",
    "    # 검증데이터를 앞에서 구한 샘플의 갯수만큼 잘라봅시다.\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_labels = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    # 검증데이터를 제외하고 나머지는 전부 학습데이터로 쓰면 됩니다. 3조각으로 나눠진 데이터를 합치려면 어떻게 해야할까요?\n",
    "    data1 = train_data[:i * num_val_samples]\n",
    "    # print(0,i * num_val_samples)\n",
    "    data2 = train_data[(i+1) * num_val_samples :]\n",
    "    # print((i+1) * num_val_samples, 404)\n",
    "    # 라벨도 합쳐줍시다.\n",
    "    data1_labels = train_labels[:i * num_val_samples]\n",
    "    data2_labels = train_labels[(i+1) * num_val_samples :]\n",
    "\n",
    "    partial_train_data = np.concatenate([data1, data2], axis=0)\n",
    "    partial_train_labels = np.concatenate([data1_labels, data2_labels], axis=0)\n",
    "    \n",
    "    # 이제 학습시켜 봅시다.\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(partial_train_data, partial_train_labels, epochs=500, batch_size=128, verbose=0)  # verbose는 훈련상황을 보여줄거냐 말거냐 입니다.\n",
    "    \n",
    "    # 그리고 모델을 검증해봅시다.\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_labels)\n",
    "    print(val_mse, val_mae)\n",
    "    all_scores.append(val_mae)  # 아까 만들어 놓은 리스트 객체에 누적추가할 수 있도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6bee1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.956292152404785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
