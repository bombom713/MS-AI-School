{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4d1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5c46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4963ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.0.1+cpu)\n",
      "    Python  3.8.10 (you have 3.8.16)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875e680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany.\n",
    "Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead!\n",
    "As a lifelong enemy of the Decepticons, I hope you can understand my dilemma.\n",
    "To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
    "Enclosed are copies of my records concerning this purchase.\n",
    "I expect to hear from you soon.\n",
    "Sincerely,\n",
    "Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8626eb5",
   "metadata": {},
   "source": [
    "감정분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737e5d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE 0.9015464782714844\n"
     ]
    }
   ],
   "source": [
    "outputs = classifier(text)\n",
    "for output in outputs:\n",
    "    print(output[\"label\"], output[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28faadf",
   "metadata": {},
   "source": [
    "개체명 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad652cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity_group     score           word  start  end\n",
      "0          ORG  0.879011         Amazon      5   11\n",
      "1         MISC  0.990859  Optimus Prime     36   49\n",
      "2          LOC  0.999755        Germany     90   97\n",
      "3         MISC  0.556570           Mega    208  212\n",
      "4          PER  0.590255         ##tron    212  216\n",
      "5          ORG  0.669692         Decept    253  259\n",
      "6         MISC  0.498349        ##icons    259  264\n",
      "7         MISC  0.775362       Megatron    350  358\n",
      "8         MISC  0.987854  Optimus Prime    367  380\n",
      "9          PER  0.812096      Bumblebee    502  511\n"
     ]
    }
   ],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "outputs = ner_tagger(text)\n",
    "temp = pd.DataFrame(outputs)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd86598",
   "metadata": {},
   "source": [
    "추출적 질문답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07c3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  start  end                   answer\n",
      "0  0.387484    335  358  an exchange of Megatron\n"
     ]
    }
   ],
   "source": [
    "reder = pipeline(\"question-answering\")\n",
    "question = \"What dose the customer want?\"\n",
    "outputs = reder(question=question, context=text)\n",
    "temp1 = pd.DataFrame([outputs])\n",
    "print(temp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f64d6",
   "metadata": {},
   "source": [
    "텍스트 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fa5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee demands an exchange of Megatron for an Optimus Prime figure he bought from the online store in Germany. The Decepticons are a lifelong enemy of the Decepticon, and Bumblebe is a lifelong foe of the Autobot. Bumblebumblebe demands an\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "outputs = summarizer(text, max_length=60, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d6a4e",
   "metadata": {},
   "source": [
    "번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01069f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d371d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e69c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --force-reinstall charset-normalizer==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801eee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d502fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14b9838cc004480a573405f6c635297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/790k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b91ae870b842fe97c7356704e4d5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/815k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff78faf0380d40aa93604f6f8115907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/959k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acfcb361f23429586d208316456bb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bomi\\anaconda3\\envs\\AI\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.'}]\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-en-ko\")\n",
    "print(pipe(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe9c4a7",
   "metadata": {},
   "source": [
    "텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1219be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cb90695",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de023966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9949fa6997480db3f0e5b7c2e40cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dea993cccc641ec95b1a33cc212b028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866cf83b82f3495d8730815102dae45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578f2a78b99c48fb9e020cc0a51461a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d509607ee824dd88fb6adc2a2a7d61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcf1d46311242e3b5779e3aaabd094e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany.\n",
      "Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead!\n",
      "As a lifelong enemy of the Decepticons, I hope you can understand my dilemma.\n",
      "To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
      "Enclosed are copies of my records concerning this purchase.\n",
      "I expect to hear from you soon.\n",
      "Sincerely,\n",
      "Bumblebee.\n",
      "\n",
      "Customer service response: \n",
      "Dear Bumblebee, I am sorry to hear that your order was mixed up. You have requested a new Transformers 2 action figure and the Optimus Prime action figure I received on June 17 was not a part of this purchase. After all, I did not have an Optimus Prime action figure in my collection in the past, so this was not included in the purchase. I can confirm\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    "prompt = text + \"\\n\\nCustomer service response: \\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edb0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
